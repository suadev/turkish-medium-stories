
# Microservice Mimariâ€™lerde Loglama

image from memegenerator.net

Ã–nceki yazÄ±larÄ±mda da sÄ±k sÄ±k deÄŸindiÄŸim gibi daÄŸÄ±tÄ±k sistemlerde bir Ã§ok sorun iÃ§in tek ve kolay bir Ã§Ã¶zÃ¼m yoktur. Loglama konusu da bunlardan bir tanesi.

Bu yazÄ±da loglama iÃ§in mimarimizi nasÄ±l oluÅŸturmalÄ±yÄ±z, **best practice**â€™ler nelerdir sorularÄ±na yanÄ±t arayacaÄŸÄ±z. Burada bahsedeceÄŸim konularÄ±n bir Ã§oÄŸu sadece **Microservices** uygulamalara Ã¶zel ÅŸeyler olmayacak, dolayÄ±sÄ±yla **monolith **mimaride uygulama geliÅŸtirenler iÃ§in de ilgi Ã§ekici olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum. Konuyu iki ana baÅŸlÄ±kta ele alacaÄŸÄ±z;

* Loglama Ãœzerine Genel Tavsiyeler

* UÃ§tan Uca Loglama Mimarisi

### Logalama Ãœzerine Genel Tavsiyeler

Microservice Mimariâ€™leri daÄŸÄ±tÄ±k sistemlerin bir tÃ¼rÃ¼ olarak ele alabiliriz. DaÄŸÄ±tÄ±k sistemlerde her bir servisi ve bu servisin Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ± sunucuyu **trace** etmek **(**izlemek**), **beklenmedik durumlarda hatanÄ±n kaynaÄŸÄ±na hÄ±zlÄ± ve etkili ÅŸekilde inebilmek iÃ§in Ã§ok Ã¶nemlidir.

Servislerimizin her birisi farklÄ± bir sunucuda sunulurken, oluÅŸan uygulama loglarÄ±mÄ±z da haliyle daÄŸÄ±tÄ±k yapÄ±da olacaktÄ±r. Buna ek olarak bir de **cloud **Ã¼zerinde **auto-scaled** bir yapÄ±nÄ±z varsa, o zaman hangi log hangi sunucuda ve ne zaman oluÅŸmuÅŸ gibi sorularÄ±n yanÄ±tÄ±nÄ± almak iÃ§in biraz daha fazla efor harcamanÄ±z gerekiyor. Zira bildiÄŸiniz gibi **auto-scale** yapÄ±da yÃ¼k durumuna gÃ¶re dinamik olarak yeni sunucular Ã§ok kÄ±sa sÃ¼rede devreye alÄ±nÄ±p aynÄ± ÅŸekilde kapatÄ±labiliyor. Loglama mimarimizi, bu kapatÄ±lan sunucularda log kaybÄ± yaÅŸamamak Ã¼zere kurgulamamÄ±z gerekmekte. Yani kÄ±saca clusterâ€™Ä±nÄ±zÄ±n auto-scale olup olmamasÄ± da mimariyi kurgularken gÃ¶z Ã¶nÃ¼nde bulundurmamÄ±z gereken konulardan birisi olmalÄ±.

### LoglarÄ±n MerkezileÅŸtirilmesi

YapÄ±mÄ±z daÄŸÄ±tÄ±k bir yapÄ± olduÄŸundan, ilk dÃ¼ÅŸÃ¼nmemiz gereken konu tÃ¼m servislerimizin Ã¼rettiÄŸi loglarÄ±n tek yerden eriÅŸilebilir olmasÄ±dÄ±r. Bir servisin logunu fileâ€™a, bir diÄŸerinin DBâ€™ye bir baÅŸkasÄ±nÄ±n kuyruÄŸa yazdÄ±ÄŸÄ± bir ortamda oluÅŸan bir hatanÄ±n kaynaÄŸÄ±na inmek saatler alabilir.

MerkezileÅŸtirme iÃ§in Ã§eÅŸitli yÃ¶ntemler mevcut. Mimari bÃ¶lÃ¼mÃ¼nde biraz daha detaylÄ± ele alacaÄŸÄ±mÄ±z iÃ§in burada sadece kaÃ§Ä±nmamÄ±z gereken bir **bad practiceâ€™**den bahsetmek isterim.

Microservice Mimariâ€™yi uygularken, isteriz ki servislerimiz atomik olsun, yani sadece bir iÅŸe, bir domainâ€™e odaklansÄ±n. DiÄŸer servislere baÄŸÄ±mlÄ±lÄ±ÄŸÄ± sÄ±fÄ±r noktasÄ±nda olsun. Hal bÃ¶yleyken her tÃ¼rlÃ¼ ihtiyaÃ§ iÃ§in irili ufaklÄ± servisler oluÅŸturmaya baÅŸlarÄ±z. Ä°ÅŸ loglamaya geldiÄŸinde de yine bir http log service oluÅŸturup loglama iÅŸini de bu servise yÃ¼kleyerek diÄŸer tÃ¼m servislerin bu servis Ã¼zerinden log atmasÄ±nÄ± isteyebiliriz. Ä°lk bakÄ±ÅŸta her ÅŸey normalmiÅŸ gibi gÃ¶zÃ¼kse de servis sayÄ±sÄ±, dolayÄ±sÄ±yla Ã¼retilen log miktarÄ± arttÄ±kÃ§a loglama iÅŸlemi iÃ§in oluÅŸan http trafiÄŸi baÅŸ aÄŸrÄ±sÄ± olabiliyor. Yani bu maddeden Ã§Ä±karacaÄŸÄ±mÄ±z ders, loglama iÅŸini Ã¼stlenen bir http service oluÅŸturmaktan kaÃ§Ä±nmamÄ±z gerektiÄŸi.

### MerkezileÅŸtirme Ä°Ã§in Aggregation Tool Kullanma

**Log Aggregation **araÃ§larÄ±, tÃ¼m loglarÄ±mÄ±zÄ± tek bir ortak lokasyonda ve benzer formatta birleÅŸtirme ihtiyacÄ± Ã¼zerine ortaya Ã§Ä±kmÄ±ÅŸtÄ±r. Bu birleÅŸtirme iÅŸi iÃ§in farklÄ± yÃ¶ntemler mevcut. Burada seÃ§eceÄŸiniz yÃ¶ntem, servis loglarÄ±nÄ±zÄ± nerede ve nasÄ±l tuttuÄŸunuza gÃ¶re belirlenecektir.

Ã–rneÄŸin, siz her servisin kendi sunucusunda bir dizine .txt olarak log atmasÄ±na karar verdiniz. Bu loglarÄ± birleÅŸtirme iÃ§in bir job yazar, belirli aralÄ±klarla tek ortak bir dizine tÃ¼m txtâ€™leri toplayabilirsiniz. Tercih kÃ¶tÃ¼ olsa bile sonuÃ§ta bir **log aggregation** yapmÄ±ÅŸ olursunuz aslÄ±nda.

Daha doÄŸru olan ise, bu iÅŸ iÃ§in geliÅŸtirilen Ã¼cretli veya Ã¼cretsiz bir araÃ§ kullanmanÄ±z yÃ¶nÃ¼nde. **ELK (elastic search, logstash,kibana) **stackâ€™inin aggregation aracÄ± olan **logstash**â€™i Ã¶nerebilirim mesela. ELKâ€™dan, mimari bÃ¶lÃ¼mde bahsedeceÄŸimiz iÃ§in burada fazla detaya girmiyorum

### Logâ€™daki TÃ¼m AlanlarÄ±n Aranabilir OlmasÄ±

LoglarÄ±nÄ±zÄ± sorgularken bazÄ± alanlar Ã¼zerinden daha sÄ±k sorgulama yapmanÄ±z gayet doÄŸaldÄ±r. Ancak siz her durumda mevcut alanlarÄ±n tÃ¼mÃ¼ Ã¼zerinden sorgulama yapabilecek ve hÄ±zlÄ±ca yanÄ±t alabilecek bir yapÄ± oluÅŸturmaya odaklanÄ±rsanÄ±z iyi edersiniz.

HÄ±z iÃ§in veritabanÄ± Ã¼zerinde index oluÅŸturma tabi ilk aklÄ±mÄ±za gelen Ã§Ã¶zÃ¼m. **CustomerId**, **UserId**, **LogLevel **gibi alanlar Ã¼zerinden indexâ€™lenme olmazsa olmazdÄ±r, ancak kritik bir anda Ã¶rneÄŸin **InstanceId **alanÄ± Ã¼zerinden sorgulama yapmanÄ±z gerekirse, dakikalarca beklemek biraz can sÄ±kÄ±cÄ± olabilir.

EÄŸer Ã§Ã¶zÃ¼m index oluÅŸturmaksa neden tÃ¼m alanlar iÃ§in oluÅŸturmuyoruz diye dÃ¼ÅŸÃ¼nebilirsiniz. Indexâ€™leme iÅŸi maliyetlidir. Ã‡ok fazla veya Ã§ok bÃ¼yÃ¼k boyutlu indexâ€™ler memoryâ€™de bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re yer kaplayacaktÄ±r. Ãœstelik bununla da kalmaz, her bir insert/delete/update komutundan sonra bu indexlerin gÃ¼ncellenmesi gerekmektedir. Bu da sizin insert/delete/update sÃ¼relerinizin uzamasÄ±na yol aÃ§abilir.

Ancak bu indexâ€™leme iÅŸini uygulama veritabanÄ±nda deÄŸil de ,bir log aggregation aracÄ± Ã¼zerinde yaparsanÄ±z performans kaybÄ±nÄ±n Ã¶nÃ¼ne geÃ§ebilirsiniz.

### Log Seviyesinin (Log Level) Dinamik AyarlanmasÄ±

AtÄ±lan her bir satÄ±r logâ€™un mevcut kaynaklarÄ±nÄ±zÄ± tÃ¼kettiÄŸini ve aynÄ± zamanda log sorgulama maliyetinizi (sÃ¼resini) artÄ±rdÄ±ÄŸÄ±nÄ± unutmamanÄ±z gerekiyor. Bu baÄŸlamda, servislerimiz ayaktayken, **runtimeâ€™**da log seviyemizi dinamik olarak,uygulamamÄ±zÄ± kesintiye uÄŸratmadan deÄŸiÅŸtirmek isteyebiliriz. Elbette kullandÄ±ÄŸÄ±mÄ±z yardÄ±mcÄ± kÃ¼tÃ¼phanenin (varsa) bunu destekliyor olmasÄ± gerekmekte.

Bu Ã¶zelliÄŸi aÄŸÄ±rlÄ±klÄ± olarak **Production** ortamÄ±mÄ±zda kullanabiliriz. Ã–rneÄŸin geÃ§ici bir sÃ¼reliÄŸine Debug seviyesinde log atÄ±lmasÄ±nÄ± isteyebiliriz. Servisimiz ayaÄŸÄ± kalkarken en detaylÄ± log seviyesini pasife Ã§ekip, sonrasÄ±nda aktif hale getirerek aslÄ±nda bize bir faydasÄ± dokunmayan, gereksiz bir sÃ¼rÃ¼ logdan kurtulabiliriz.

### Asenkron Loglama

Loglama iÅŸlemini hangi yolla yaparsanÄ±z yapÄ±n, logâ€™u atacak olan birimin asenkron Ã§alÄ±ÅŸmasÄ± uygulama performansÄ± aÃ§Ä±sÄ±ndan Ã¶nemlidir.

Asenkron loglamada, loglamayÄ± yapacak olan **logger thread**, o an yÃ¼rÃ¼tÃ¼lmekte olan transactionâ€™Ä±n (http isteÄŸinin) threadâ€™ini blockâ€™lamayacaÄŸÄ± iÃ§in herhangi bir performans kaybÄ±na neden olmayacaktÄ±r. Ek olarak uygulamanÄ±zÄ±n loglama iÅŸleminin sonucuyla da ilgilenmemesi gerekiyor. Bir baÅŸka deyiÅŸle loglar **fire-and-forget** prensibi ile gÃ¶nderilmelidir.

### CorrelationId KullanÄ±mÄ±

Bir transactionâ€™Ä±n icra edilmesi iÃ§in arka planda 3â€“5 farklÄ± web servisin birbirlerini tetiklediÄŸi bir senaryoyu ele alalÄ±m. Burada yapÄ±lan iÅŸlem aslÄ±nda tek bir iÅŸlem. Ã–rneÄŸin bir satÄ±n alma iÅŸlemi. Ancak arka planda 5 farklÄ± servis Ã§alÄ±ÅŸmakta ve, 5 adet log atÄ±ldÄ±ÄŸÄ±nÄ± biliyoruz. Bu iÅŸlemin loglarÄ±na eriÅŸmek istediÄŸimizde bu 5 adet log iÃ§in bir grup numarasÄ± olsaydÄ± ve bu no ile sorgulama yaptÄ±ÄŸÄ±mÄ±zda sadece bu 5 adet logu gÃ¶rebilseydik gÃ¼zel olurdu deÄŸil mi?

Bu gruplamayÄ± yapmak iÃ§in **X-Correlation-Id** http headerâ€™Ä±nÄ± kullanabiliriz. Bu headerâ€™a iÅŸlem bazÄ±nda **unique **bir deÄŸer set etmemiz gerekmekte. Ek olarak log tablomuza da CorrelationId adÄ±nda bir alanda eklememiz gerekiyor tabi. ArtÄ±k geriye, bu headerâ€™Ä± her servis **request** ve **responseâ€™**u** **iÃ§in doÄŸru ÅŸekilde set etmek olacaktÄ±r. Ã–rnek senaryomuzdaki 5 adet servisten her birisi bir sonraki servise bu CorrelationId deÄŸerini geÃ§ecektir. Kulaktan kulaÄŸa oyunu gibi dÃ¼ÅŸÃ¼nebilirsiniz.

Asp.Net Core ile uygulama geliÅŸtiriyorsanÄ±z [**buradaki](https://www.nuget.org/packages/CorrelationId/) **middleware iÅŸinizi gÃ¶recektir. Tabi kendi interceptorâ€™Ä±nÄ±zÄ± yazarak ta bu iÅŸi kolayca yÃ¶netebilirsiniz.

### DetaylÄ± ve AnlaÅŸÄ±labilir Log

GÃ¼n iÃ§inde bir servisin loglarÄ±nÄ± inceleme gereÄŸi duyuyorsak, bir ÅŸeyler ters gidiyor demektir, tabi istisnai durumlar olabilir. Gerek development aÅŸamasÄ±nda gerekse production ortamÄ±mÄ±zda loglar tabiri caizse elimiz ayaÄŸÄ±mÄ±z oluyor. Tabi yeteri kadar detaylÄ± bilgi verebildikleri zaman. Bu da yine bizim elimizde olan bir ÅŸey. Ã–zellikle **error log**â€™larÄ± mÃ¼mkÃ¼n olduÄŸunca detaylÄ± ve Ã¶nemli bilgi iÃ§ermelidir. DetaylÄ± yanÄ±nda Ã¶nemli de dedim Ã§Ã¼nkÃ¼ gereksiz bir sÃ¼rÃ¼ detay iÃ§eren ama hatanÄ±n kaynaÄŸÄ±na inmeye yardÄ±mcÄ± olacak bilgiyi iÃ§ermeyen logun kimseye bir faydasÄ± olmayacaktÄ±r.

SÃ¶zÃ¼n Ã¶zÃ¼, eÄŸer loglarÄ±nÄ±zÄ± incelerken â€œKeÅŸke ÅŸu bilgi de elimizde olsaydÄ± ğŸ˜Ÿâ€ diye iÃ§ geÃ§iriyorsanÄ±z, o bilgi iÃ§in de ek bir alan aÃ§manÄ±n zamanÄ± gelmiÅŸ demektir.

### Log ZamanÄ± Ä°Ã§in Utc Time KullanÄ±mÄ±

Ã–zellikle servislerin cloud Ã¼zerinde sunulduÄŸu senaryolarda, mevcut sunucularÄ±n veya yÃ¼k oluÅŸmasÄ± anÄ±nda devreye alÄ±nacak yeni sunucularÄ±n hangi time zoneâ€™da olacaÄŸÄ±yla ilgilenmek istemezsiniz. Sizin iÃ§in Ã¶nemli olan sunucunun performansÄ± ve yÃ¼ksek eriÅŸilebilirliÄŸi olacaktÄ±r.

Ancak iÅŸ loglarÄ±nÄ±zÄ± sorgulamaya gelince, log zamanÄ±nÄ±n hangi time zoneâ€™a gÃ¶re atÄ±lacaÄŸÄ± konusu Ã¶nem arz ediyor. Zamana gÃ¶re order by ettiÄŸiniz loglarÄ±n iÅŸlem sÄ±rasÄ±na gÃ¶re hatalÄ± olarak gelmesi istemezsiniz. Burada tavsiyem Utc time kullanmanÄ±zdÄ±r. BÃ¶ylece Ã§ok farklÄ± lokasyonlardaki servislerden atÄ±lan loglarda bile zaman karmaÅŸasÄ± yaÅŸamamÄ±ÅŸ olursunuz. Bu arada eÄŸer sizin iÃ§in logu atan sunucunun local zamanÄ± da Ã¶nemliyse, log veri tabanÄ±nÄ±za **TimeZone **adÄ±nda opsiyonel bir alan ekleyip time zone bilgisini de buraya yazabilirsiniz.

### Instance Id Ekleme

EÄŸer servislerinizi herhangi bir cloud provider Ã¼zerinden sunuyorsanÄ±z ve auto-scaling Ã¶zelliÄŸini kullanÄ±yorsanÄ±z, yukarÄ±da da bahsettiÄŸim gibi yÃ¼k durumuna gÃ¶re sÃ¼rekli yeni sunucular (instance) eklenip Ã§Ä±karÄ±lacaktÄ±r. Logâ€™un hangi instanceâ€™dan atÄ±ldÄ±ÄŸÄ±, logu atan sunucunun hala aktif olup olmadÄ±ÄŸÄ± gibi konular sizin iÃ§in Ã¶nemliyse, logunuza **InstanceId** alanÄ±nÄ± ekleyerek bu sorunu Ã§Ã¶zebilirsiniz.

### Log Alert Sistemi

Loglama alt yapÄ±nÄ±z artÄ±k olgunlaÅŸtÄ±, loglarÄ±nÄ±z sorunsuz ÅŸekilde akÄ±yor, sorgular gayet hÄ±zlÄ± Ã§alÄ±ÅŸÄ±yor ne mutlu size. ArtÄ±k iÅŸi bir adÄ±m Ã¶teye taÅŸÄ±mak gerekiyor.

EÄŸer canlÄ± ortamda oluÅŸan hatalarÄ±nÄ±z iÃ§in biraz daha proaktif olmak ve daha hÄ±zlÄ± aksiyon almak istiyorsanÄ±z mutlaka bir alarm sistemini devreye almanÄ±z gerekiyor. Bu sistemi saÄŸlayan Ã¼cretli Ã¼cretsiz birÃ§ok **third party** araÃ§ mevcut olmakla birlikte kendi implementasyonunuzu da pek ala yapabilirsiniz tabi.

Bu tarz alarm yapÄ±larÄ±yla Ã¶rneÄŸin, gelen log daki **LogDetail **alanÄ±nda â€œ**DB Connection Timeout**â€ hatasÄ± geÃ§iyorsa ÅŸu kiÅŸi veya kiÅŸilere slackâ€™ten mesaj at veya sms at gibi aksiyonlar alabildiÄŸimiz iÃ§in oldukÃ§a faydalÄ± olduÄŸunu sÃ¶yleyebilirim.

Alarm konusu iÃ§in bir sÃ¼re deneyimleme fÄ±rsatÄ± bullduÄŸum [**Seq](https://getseq.net/)** i incelemenizi Ã¶neririm. Tabi [**ELK ](https://www.elastic.co/elk-stack)**ile de veri deÄŸiÅŸikliklerini izleyerek aynÄ± ÅŸekilde alarm kurallarÄ± oluÅŸturabilmeniz mÃ¼mkÃ¼n.

## UÃ§tan Uca Loglama Mimarisi

Bu bÃ¶lÃ¼mde, yukarÄ±da yaptÄ±ÄŸÄ±mÄ±z Ã¶neriler Ä±ÅŸÄ±ÄŸÄ±nda Ã¶rnek bir mimari tasarlayÄ±p, Ã§izdiÄŸim diagram Ã¼zerinden yorumlamaya Ã§alÄ±ÅŸacaÄŸÄ±m.

HatÄ±rlarsanÄ±z loglamayÄ± bir servis Ã¼zerinden http request ile yapmanÄ±n kÃ¶tÃ¼ bir fikir olduÄŸundan bahsetmiÅŸtik. Ancak aynÄ± zamanda loglarÄ± bir ÅŸekilde merkezileÅŸtirmemiz gerektiÄŸini de sÃ¶yledik. YapmamÄ±z gereken ÅŸey Ã§okta karmaÅŸÄ±k deÄŸil aslÄ±nda.

Her microservice, oluÅŸturduÄŸu loglarÄ± aracÄ± bir baÅŸka http servis olmaksÄ±zÄ±n asekron olarak bir kuyruÄŸa gÃ¶nderebilir. Buradaki kuyruk, **Apache** **Kafka **veya** RabbitMQ **gibi bir **message broker **olabileceÄŸi gibi, kuyruk kullanmadan doÄŸrudan bir **RDBMS **veya **NoSQL** veritabanÄ± da olabilir. Bu tamamen sizin log yoÄŸunluÄŸuna baÄŸlÄ± olarak yaptÄ±ÄŸÄ±nÄ±z tasarÄ±ma kalmÄ±ÅŸ. Benim tavsiyem, **Kafka **veya **RabbitMQ **ikilisinden** **birini kullanmanÄ±z yÃ¶nÃ¼nde olur. EÄŸer doÄŸrudan bir veritabanÄ±na yazacaksanÄ±z da bu RDBMS yerine bir NoSQL veritabanÄ± olmalÄ±.

LoglarÄ±nÄ±zÄ± doÄŸrudan bir kuyruÄŸa gÃ¶ndererek veritabanÄ± sunucunuzu ekstra ve bÃ¼yÃ¼k bir yÃ¼kten kurtarmÄ±ÅŸ olursunuz. VeritabanÄ± sunucuunz sizin en deÄŸerli kaynaÄŸÄ±nÄ±zdÄ±r. ve unutmayÄ±n DB sunucularÄ± ramâ€™i sever yani bol bol kullanÄ±r.

Bir diÄŸer aklÄ±ma gelen konu da uygulamanÄ±z ayaÄŸÄ± kalkarken, henÃ¼z veritabanÄ± baÄŸlantÄ±sÄ± yapÄ±lmadan Ã¶nce loglamaya deÄŸer bazÄ± bilgileriniz olabilir ancak veritabanÄ± baÄŸlantÄ±sÄ± henÃ¼z saÄŸlanmadÄ±ÄŸÄ± iÃ§in bu bilgileri loglayamayacaksÄ±nÄ±z.

Kuyruk yapÄ±larÄ± AMQP protokolÃ¼nÃ¼ desteklerler. Bu protokol Httpâ€™nin aksine asenkron Ã§alÄ±ÅŸÄ±r ve mesajlarÄ± alÄ±cÄ±sÄ±na teslim etme garantisi verir. Tabi sizin kuyruÄŸu nasÄ±l konfigÃ¼re ettiÄŸiniz de Ã¶nemlidir. Bir Ã¶nceki [**yazÄ±mda](https://medium.com/devopsturkiye/microservice-mimarilerde-servisler-aras%C4%B1-i%CC%87leti%C5%9Fim-nas%C4%B1l-olmal%C4%B1-3d8db63b4dea)** AMQPâ€™den daha detaylÄ± bahsetmiÅŸtim dilerseniz inceleyebilirsiniz.

TÃ¼m bu bilgiler Ä±ÅŸÄ±ÄŸÄ±nda Ã§izdiÄŸim aÅŸaÄŸÄ±daki basit mimariyi siz de uygulamalarÄ±nÄ±z iÃ§in rahatlÄ±kla uygulayabilirsiniz.

![Microservice Uygulamalar Ä°Ã§in Loglama Mimarisi](https://cdn-images-1.medium.com/max/2586/1*egtisUJNs-xDyaN5Lw3TFQ.png)*Microservice Uygulamalar Ä°Ã§in Loglama Mimarisi*

Son olarak mimariyi oluÅŸturan bu 5 parÃ§adan kÄ±saca bahsetmek gerekirse;

### Microservices

FarklÄ± format ve yoÄŸunluklarda loglar Ã¼reten ve kuyruÄŸa gÃ¶nderen mevcut microservislerimiz mimarinin ilk bacaÄŸÄ±nÄ± oluÅŸturmakta. Dikkat ederseniz servisler ve kuyruk arasÄ±nda herhangib aracÄ± baÅŸka bir servis bulunmuyor.

### **Message Queue**

Microserviceâ€™lerimizin Ã¼rettikleri loglarÄ± **publish **ettikleri kuyruÄŸu tanÄ±mladÄ±ÄŸÄ±mÄ±z message brokerâ€™Ä±mÄ±z. Log yoÄŸunluÄŸuna gÃ¶re bu brokerâ€™larÄ± da yatayda Ã¶lÃ§ekleyebilirsiniz yalnÄ±z, Kafka yatayda Ã¶lÃ§eklenebiliyorken yanÄ±lmÄ±yorsam RabbitMQ bu imkanÄ± vermiyor. RabbitMQ da, iki farklÄ± sunucu kurup aktif-aktif Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlayabiliyorsunuz ancak yÃ¼kÃ¼ 2 suncu arasÄ±nda daÄŸÄ±tarak yatayda Ã¶lÃ§ekleneyim diyemiyorsunuz.

### **Aggregation Tool**

AslÄ±nda ELK bÃ¼tÃ¼n olarak bir log aggregation aracÄ±dÄ±r demek de yanlÄ±ÅŸ olmaz. **Logstash**, loglarÄ± ilk karÅŸÄ±layan, isteÄŸinize gÃ¶re manipÃ¼le edebilen ve sonrasÄ±nda Elasticsearchâ€™e gÃ¶nderen taraf olduÄŸu iÃ§in ben, Logstash ELK stackâ€™inin log aggregation toolâ€™udur demeyi tercih ediyorum.

### **NoSQL Document DB**

Elasticsearch, bir arama motoru gibi Ã§alÄ±ÅŸmak Ã¼zere optimize edilmiÅŸ, NoSQL document tipi veritabanÄ±dÄ±r. ELK stackâ€™inde loglarÄ±n fiziksel olarak saklandÄ±ÄŸÄ±, indexlendiÄŸi ve sorgulandÄ±ÄŸÄ± yer burasÄ±dÄ±r.

### Visualization Tool

ELK stackâ€™ini tercih ettiÄŸimiz iÃ§in loglarÄ±mÄ±zÄ± listelemek, sorgulamak ve Ã§eÅŸitli faydalÄ± grafiklerden faydalanmak iÃ§in bu stackâ€™in sunmuÅŸ olduÄŸu Kibana visualiztion toolâ€™unu kullanÄ±yoruz. Kibana, kullanÄ±ÅŸlÄ± arayÃ¼zÃ¼, log sorgularken iÅŸimizi kolaylaÅŸtÄ±ran query syntaxâ€™Ä±, oluÅŸturulan log raporlarÄ±nÄ± excel export edebilme gibi birÃ§ok Ã¶zelliÄŸi nedeniyle Facebook, Microsoft, Linkedin gibi devler tarafÄ±ndan tercih ediliyor.

Geldik bir **Microservices **yazÄ±sÄ±nÄ±n daha sonuna. Konuyla alakalÄ± farklÄ± Ã¶neri veya eleÅŸtirileriniz iÃ§in yorumlarÄ±nÄ±zÄ± beklerim.
